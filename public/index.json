[{"content":" title: learn4mongo date: 2020-08-27 16:29:24 categories:\n笔记 tags: mongo MongoDB的一些基本操作，只适用于日常开发，深入了解MongoDB请略过本文\nMongo数据库操作 在学习Mongo之后因为没有系统的做过总结，就想在此写一篇比较系统比较全面的日常操作数据库的SQL操作总结。本文实时补充\n增\n//添加语句 db.COLLECTION_NAME.insert(document) db.data.insert({ title:\u0026#39;测试添加操作\u0026#39;, by:\u0026#39;YueYang\u0026#39;, time:\u0026#39;11:08\u0026#39; }); WriteResult({ \u0026#34;nInserted\u0026#34; : 1, \u0026#34;writeConcernError\u0026#34; : [ ] }) 删\n// 删除操作 db.collection.remove( \u0026lt;query\u0026gt;, { justOne: \u0026lt;boolean\u0026gt;, writeConcern: \u0026lt;document\u0026gt; } ) db.data.remove({ by:\u0026#39;YueYang\u0026#39; }); WriteResult({ \u0026#34;nRemoved\u0026#34; : 1, \u0026#34;writeConcernError\u0026#34; : [ ] }) 改\n// 更改操作 db.collection.update( \u0026lt;query\u0026gt;, \u0026lt;update\u0026gt;, { upsert: \u0026lt;boolean\u0026gt;, multi: \u0026lt;boolean\u0026gt;, writeConcern: \u0026lt;document\u0026gt; } ) db.data.update({\u0026#34;title\u0026#34;:\u0026#34;测试添加操作\u0026#34;},{$set:{\u0026#34;title\u0026#34;:\u0026#34;测试更新操作\u0026#34;}}); WriteResult({ \u0026#34;nMatched\u0026#34; : 1, \u0026#34;nUpserted\u0026#34; : 0, \u0026#34;nModified\u0026#34; : 1, \u0026#34;writeConcernError\u0026#34; : [ ] }) db.data.update({\u0026#34;title\u0026#34;:\u0026#34;测试添加操作\u0026#34;},{$set:{\u0026#34;title\u0026#34;:\u0026#34;测试更新操作\u0026#34;}},{multi:true}); WriteResult({ \u0026#34;nMatched\u0026#34; : 2, \u0026#34;nUpserted\u0026#34; : 0, \u0026#34;nModified\u0026#34; : 2, \u0026#34;writeConcernError\u0026#34; : [ ] }) 查\n// 查询操作 db.data.find({\u0026#34;by\u0026#34;:\u0026#34;YueYang\u0026#34;}); _id title by\ttime 5dafd24abc1b000007001bf7\t测试更新操作\tYueYang\t11:08 5dafd2e5bc1b000007001bf8\t测试更新操作\tYueYang\t12:10 条件查询\n大于\t$gt 小于\t$lt 大于等于 gte 小于等于\t$lte 不等于\t$ne 等于\t$eq 包含于 $in db.data.find({age: {$gt : 18}}); -- select * from data where age \u0026gt; 18; 模糊查询\n查询 title 包含\u0026#34;测试\u0026#34;字的文档： db.data.find({title:/测试/}); 查询 title 字段以\u0026#34;教\u0026#34;字开头的文档： db.data.find({title:/^测试/}); 查询 titl e字段以\u0026#34;教\u0026#34;字结尾的文档： db.data.find({title:/教$/}); 模糊查询查询字段掌握了正则表达式就很容易扩展出来啦~ 三种正则表达式方式：\n{ \u0026lt; field \u0026gt;： { $ regex ： / pattern / ， $ options ： ‘’ } } { \u0026lt; field \u0026gt;： { $ regex ： ‘pattern’ ， $ options ： ‘’ } } { \u0026lt; field \u0026gt; ： { $ regex ： / pattern / \u0026lt; options \u0026gt; } } 排序\n// 数据排序 db.data.find().sort({title:1}); // 其中 1 为升序排列，而 -1 是用于降序排列 分组操作\ndb.data.aggregate([{ $group: { _id: { title: \u0026#39;$title\u0026#39;, by: \u0026#39;$by\u0026#39; }, count: { $sum: 1 } } }, { $match: { count: { $gt: 1 } } }]); $group 将集合中的文档分组，可用于统计结果 _id表示分组的依据，使用某个字段的格式为\u0026#39;$字段\u0026#39;。 $match 用于过滤数据，只输出符合条件的文档 删除重复数据\n// 前面写查询语句，对结果数据进行去重 .forEach(function(it) { it.dups.shift(); db.data.remove({ _id: { $in: it.dups } }); }); 问题：\n删除_id失败？\n对id直接进行remove删除失败，是因为id是ObjectId类型，而id是字符串类型，类型对应不上就会导致删除失败。\n解决方法就是把id转换成ObjectId：\ndb.data.remove({_id:ObjectId(\u0026#39;1013\u0026#39;)}); ","permalink":"http://localhost:1313/posts/learn4mongo/","summary":"\u003chr\u003e\n\u003cp\u003etitle: learn4mongo\ndate: 2020-08-27 16:29:24\ncategories:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e笔记\ntags:\n\u003cul\u003e\n\u003cli\u003emongo\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003eMongoDB的一些基本操作，只适用于日常开发，深入了解MongoDB请略过本文\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Learn4mongo"},{"content":" 整理 vim ide 的新手学习过程\nvim 一般模式可用的按钮说明 移动光标 「h、j、k、l」分别控制光标左、下、上、右移一格 「ctrl+b」屏幕往\u0026quot;后\u0026quot;移动一页 「ctrl+f」屏幕往\u0026quot;前\u0026quot;移动一页 「n」光标向右移动n个字符 「Home」移动到这一行的最前面字符处:0数字，但不能用数字小键盘上的数字 「End」移动到这一行的最后面字符处:$，我测试好像不行 「w」光标跳到下个字的开头 「e」光标跳到下个字的字尾 「H」光标移动到这个屏幕的最上方那一行的第一个字符 「M」光标移动到这个屏幕的中间那一行的第一个字符 「L」光标移动到这个屏幕的最下方那一行的第一个字符 「G」移动到这个文件的最后一行 「nG」移动到这个文件的第n行(可配合:set nu) 「gg」移动到这个文件的第一行，相当于1G 「n」光标向下移动n行\n查找与替换 「/word」向光标向下寻找一个名称为word的字符串 「?word」向光标向上寻找一个名称为word的字符串 「n」代表重复前一个查找的动作 「N」与n刚好相反，为「反向」进行行前一个查找动作 「:n1,n2s/word1/word2/g」n1与n2为数字，在第n1与n2行之间查找word1 这个字符串，并将该字符串替换为word2 「:1,$s/word1/word2/g」从第一行到最后一行查找word1字符串，并将该字符串替换为word2 「:1,$s/word1/word2/gc」从第一行到最后一行查找word1字符串，并将该字符串替换为word2 ，且在替换前提示用户确认是否进行替换\n删除、复制与粘贴 「x」为向后删除一个字符 (相当于「del」键) 「X」为向前删除一个字符(相当于「backspace」键) 「nx」连续向后删除n个字符 「dd」删除光标所在行 「ndd」删除光标所在的向下n行 「d1G」删除光标所在行到第一行的所有数据 「dG」删除光标所在到最后一行的所有数据 「d$」删除光标所在处，到该行的最后一个字符 「d0」删除光标所在处，到该行的最前一个字符 「yy」复制光标所在的那一行 「nyy」复制光标所在的向下n列 「y1G」复制光标所在行到第一行的所有数据 「yG」复制光标所在行到最后一行的所有数据 「y0」复制光标所在的那个字符到该行行首的所有数据 「y$」复制光标所在的那个字符到该行行尾的所有数据 「p」将已复制的数据在光标下一行粘贴上 「P」则为贴在光标的上一行 「u」恢复前一个操作 「Ctrl+r」重做上一个操作 「.」是重复前一个操作\n一般模式切换到编辑模式的可用的按钮说明 「i, I」进入编辑模式：\ni 为「从目前光标所在处插入」 I 为「在目前所在行的第一个非空格符处开始插入」 「a, A」进入编辑模式(Insert mode)： a 为「从目前光标所在的下一个字符处开始插入」 A 为「从光标所在行的最后一个字符处开始插入」 「o, O」进入编辑模式： o 为「在目前光标所在的下一行处插入新的一行」 O 为在目前光标所在处的上一行插入新的一行 「r, R」进入取代模式： r 只会取代光标所在的那一个字符一次 R会一直取代光标所在的文字，直到按下 ESC 为止； 「Esc」退出编辑模式，回到一般模式 一般模式切换到命令行模式可用的按钮说明 「:w」保存编辑的内容 「:w!」强制写入该文件，但跟你对该文件的权限有关 「:q」离开vi 「:q!」不想保存修改强制离开 「:wq」保存后离开 「:x」保存后离开 「ZZ」若文件没有更动，则不保存离开，若文件已经被更改过，则保存后离开 「:w filename」将编辑的数据保存成另一个文件（类似另存） 「:r filename」在编辑的数据中，读入另一个文件的数据。即将「filename」这个文件的内容加到光标所在行后面。 「:n1,n2 w filename」将n1到n2的内容保存成filename这个文件。 「:! command」暂时离开vi 到命令行模式下执行command的显示结果！例如 「:! ls /home」即可在 vi 当中察看/home底下以ls输出的文件信息！ 「:set nu」显示行号 「:set nonu」与 set nu 相反，为取消行\nvim plugins nerdtree 「ctrl+w+r」切换当前窗口左右布局 「ctrl」+p 模糊搜索文件 「gT」切换到前一个tabgT 「gt」切换到后一个tab 「o」打开关闭文件或者目录，如果是文件的话，光标出现在打开的文件中 「O」打开结点下的所有目录 「X」合拢当前结点的所有目录 「x」合拢当前结点的父目录 「i」水平分割窗口打开文件 「s」纵向分割窗口打开文件 「u」打开上层目录 「t」在标签页中打开 「T」在后台标签页中打开 「p」到上层目录 「P」到根目录 「K」到同目录第一个节点 「J」到同目录最后一个节点 「m」显示文件系统菜单（添加、删除、移动操作） 「?」帮助 「:q」关闭\n","permalink":"http://localhost:1313/posts/learn4vim/","summary":"\u003cblockquote\u003e\n\u003cp\u003e整理 vim ide 的新手学习过程\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Learn4vim"},{"content":" 整理 linux 的学习过程, 尝试通过单词全拼来理解命令含义\n命令 cal = CALendar calendar 日历 cat = CATenate 链接 该更多的情况是将文件内容输出以及合并多个文件内容 cd = Change Directory 更改目录 chgrp = CHange GRouP 改变组 chmod = CHange MODe 改变模式 chown = CHange OWNer 更改所有者 chsh = CHange SHell 更改壳 cmp = compare 比较 comm = common 常见的 cp = CoPy 复制 cpio = CoPy In and Out 拷贝进出 # 在当前目录以及所有子目录中查找文件, 并将它们放入名为 archive.cpio 的归档文件中 find . -depth -print | cpio -ov \u0026gt; archive.cpio # 这个命令会从名为 archive.cpio 的归档文件中提取所有文件, 并解压到当前目录中 cpio -idv \u0026lt; archive.cpio # 这个命令会列出名为 archive.cpio 的归档文件中包含的所有文件列表 cpio -itv \u0026lt; archive.cpio cpp = C Pre Processor C预处理器 cron = Chronos 希腊文时间, 用于执行定时任务 cron 的配置文件为 /etc/crontab, 这个文件定义了系统级别的计划任务. 而每个用户都可以使用 crontab 命令来创建自己的计划任务表(也就是 crontab 文件), 这些任务只对该用户有效 daemon = Disk And Execution MONitor 磁盘和执行监视器 dc = Desk Calculator 桌上计算器(逆波兰式计算器) dd = Disk Dump 磁盘转储 df = Disk Free 查看磁盘空间使用情况 df -h # 选项表示以可读的方式输出结果, 易于阅读 diff = DIFFerence 差异 # 基本语法 diff file1 file2 # 额外参数 diff -c file1 file2 # 以上下文模式输出差异信息 diff -u file1 file2 # 以合并模式输出差异信息 diff -i file1 file2 # 忽略大小写进行比较 diff -B file1 file2 # 忽略空格进行比较 diff -w file1 file2 # 忽略所有空白字符进行比较 du = Disk Usage 磁盘使用 du [-Aclnx] [-H | -L | -P] [-g | -h | -k | -m] [-a | -s | -d depth] [-B blocksize] [-I mask] [-t threshold] [file ...] 下面对这些参数和选项进行一一解释： -A : 将大文件(超过2GB)的大小正确计算为1KB, 而不是512字节； -c : 显示指定文件或目录总共的大小； -l : 统计符号链接占据磁盘空间的大小, 而不是链接指向的文件的大小； -n : 不递归显示大小； -x : 显示当前文件系统的大小, 不会统计挂载在其上的其他文件系统的大小； -H : 递归处理命令行中指定的目录, 当遇到符号链接时, 直接使用链接所指向的文件的大小； -L : 与 -H 类似, 但是当遇到符号链接时, 直接计算链接本身的大小； -P : 与 -H 和 -L 相反, 不跟踪任何符号链接, 直接计算链接本身的大小； -g, -h, -k, -m : 以不同的大小单位显示输出结果(用于人类可读) -a : 显示所有文件和目录的大小； -s : 只显示目录总大小, 不显示各子目录和文件的大小； -d depth : 指定显示目录树的深度, 即子目录的最大层数； -B blocksize : 指定块大小, 以字节为单位； -I mask : 指定忽略某些文件或目录(按照 shell 的语法来进行匹配)； -t threshold : 只对大于或等于指定大小的文件和目录进行计算磁盘空间使用情况 注意：在使用 du 命令时, 请谨慎选择文件或目录, 不要将它用于根目录 (\u0026#34;/\u0026#34;) 或 \u0026#34;/home\u0026#34; 等包含大量文件的目录, 否则可能会导致系统崩溃或性能下降 ed = editor 编辑 egrep = Extended GREP 扩展的grep emacs = Editor MACroS 编辑宏, 一款强大的编辑器, 和 vim 并称两大最强编辑器 eval = EVALuate 用于将命令行参数作为 shell 命令来执行 mycmd=\u0026#34;ls\u0026#34; \u0026amp;\u0026amp; eval result=$mycmd \u0026amp;\u0026amp; echo $result ex = EXtended 是一个文本编辑器, 是 vi 编辑器的前身. ex 编辑器相对来说比较老旧, 因为现在更常用的文本编辑器是 vi、nano、emacs 等 exec = EXECute 执行 # 它用于执行一个命令并替换当前 shell 进程(即将当前进程替换为指定命令). exec 命令通常在 shell 脚本中使用, 可以用于执行其他程序并将其输出/错误输出重新定向到脚本中。 # 具体来说, 当你执行 exec 命令时, 它会首先关闭当前的 shell 进程, 然后创建一个新的进程来运行指定的命令, 这个新的进程将继承当前 shell 进程的环境变量和文件描述符等信息。因此, 通过 exec 命令可以让脚本中的命令取代 shell 进程, 从而达到更高效的执行效果。 fd = file descriptors 文件描述符 fg = ForeGround 前景 fgrep = Fixed GREP 固定grep(非正则表达式匹配) fish = the Friendly Interactive SHell 是一款现代化的、用户友好的命令行 Shell file = file 查看文件类型, 是否是二进制等 fmt = format 格式化文件 grep = Global Regular Expression Print 全局正则表达式打印 ksh = Korn SHell 是一个Unix和Linux系统上的命令行解释器和编程语言。它是由David Korn开发的，旨在提供一种功能更强大的shell，用于代替传统的Bourne shell和C shell。 lex = LEXical analyser 词法分析器 ln = LiNk ls = list 列出当前或指定目录下的文件和目录 ls -l # 以长格式列出文件和目录信息，包括文件类型、权限、拥有者、大小、日期等 ls -a # 列出所有文件和目录，包括 . 开头的隐藏文件和目录 ls -h # 以易读的方式显示文件和目录的大小 ls -t # 按修改时间排序，最近修改的文件或目录先显示 ls -r # 反向排序，从后往前排列 # $ which ls # ls: aliased to ls -G lsof = LiSt Open Files 列出打开的文件, 并显示哪些进程打开了这些文件 lsof -p 100 # 显示指定 PID 的进程打开的文件信息。 lsof -u yueyang # 显示指定用户打开的文件信息 lsof -c name # 列出指定进程名字的进程打开的所有文件 lsof -i # 列出所有网络连接相关的文件 lsof -n # 不进行DNS解析，直接使用IP地址 make = make 配合 makefile 使用的命令行工具 man = MANual pages 手册, 用于查看帮助文档 mc = Midnight Commander \u0026ldquo;午夜指挥官\u0026rdquo;, 可用于浏览和管理Linux或Unix操作系统中的文件和目录 mkfs = MaKe FileSystem 使文件系统 mknod = MaKe NODe 使节点 motd = Message of The Day 当天的信息 mozilla = MOsaic GodZILLa mtab = Mount TABle 安装表 mv = MoVe nano = Nano’s ANOther editor 纳米的另一个编辑 nawk = New AWK nl = Number of Lines nm = names nohup = No HangUP 用于运行一个命令，使其不受终端关闭或网络中断的影响而继续在后台运行 nroff = New ROFF od = Octal Dump 该命令的名称由来 passwd = PASSWorD pg = pager pico = PIne’s message COmposition editor 松的消息组合编辑器 pine = “Program for Internet News \u0026amp; Email” = “Pine is not Elm” ping = Packet InterNet Groper ping程序 pirntcap = PRINTer CAPability 打印机的能力 popd = POP Directory pr = pre printf = PRINT Formatted ps = Processes Status 展示进程信息 ps # 列出当前终端下所有进程的信息。 ps -e # 列出系统上所有进程的信息，不仅限于当前终端。 ps -f # 以全格式列出进程的信息，包括进程的UID、PID、PPID、C、STIME、TTY、TIME和CMD等。 ps -aux # 列出所有进程信息，包括其他用户的进程，并显示更详细的CPU和内存占用情况。 ps -ejH # 列出所有进程及其子进程，用树状结构表示。 ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,comm # 自定义显示进程的信息，包括进程的PID、线程ID、调度类、实时优先级、静态优先级、绑定的处理器、CPU占用率、进程状态、等待的系统调用和进程命令等。 pty = pseudo tty pushd = PUSH Directory pwd = Print Working Directory 打印工作目录 rc = runcom = run command rev = REVerse rm = ReMove rn = Read News roff = RunOFF rpm = RPM Package Manager = RedHat Package Manager RedHat软件包管理器 rsh, rlogin, rvim中的r = Remote rxvt = ouR XVT seamoneky = 我 sed = Stream EDitor seq = SEQuence shar = SHell ARchive slrn = S-Lang rn ssh = Secure SHell ssl = Secure Sockets Layer stty = Set TTY su = Substitute User 或 Switch User(前者较常见) sudo = superuser / substitue user do 在ubuntu下更倾向于superuser, 因为它代表了root权限 svn = SubVersioN tar = Tape ARchive tcsh = TENEX C shell tee = T (T形水管接口) telnet = TEminaL over Network termcap = terminal capability terminfo = terminal information tex = τέχνη的缩写, 希腊文art tr = translate troff = Typesetter new ROFF 照排机新Roff tsort = Topological SORT tty = TeleTypewriter twm = Tom’s Window Manager tz = TimeZone udev = Userspace DEV ulimit = User’s LIMIT umask = User’s MASK uniq = UNIQue vi = VIsual = Very Inconvenient 很不方便 vim = Vi IMproved wall = write all wc = Word Count wine = WINE Is Not an Emulator 酒不是一个模拟器 xargs = eXtended ARGuments 扩展参数 xdm = X Display Manager X显示管理器 xlfd = X Logical Font Description 逻辑字体描述 xmms = X Multimedia System X多媒体系统 xrdb = X Resources DataBase X资源数据库 xwd = X Window Dump X窗口转储 yacc = yet another compiler compiler 另一个编译器的编译器 ","permalink":"http://localhost:1313/posts/learn4linux/","summary":"\u003cblockquote\u003e\n\u003cp\u003e整理 linux 的学习过程, 尝试通过单词全拼来理解命令含义\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Learn4linux"},{"content":" 本文目的是记录我从 Java 开发转 Golang 开发的学习经历，分享一下学习过程来帮助想要 Java 转 Golang 的朋友一起进步一起学习！\n0、安装配置 下载地址：https://golang.google.cn/dl/\n下载好了用go version来校验\n配置环境：GOPATH、Path\n配置好了用go env来校验\n1、Golang基础 优势： 并发编程优雅简单：Go语言原生支持协程（goroutine）和管道（channel），并提供了灵活而简单的并发编程机制。使用goroutine可以让我们非常方便地实现高并发、高性能的服务，同时也能有效避免线程安全问题。 零值机制：天生就有初始值，不用考虑空值情况。 内存管理自动化：Go语言的垃圾回收机制使得开发者可以不用关心内存的回收问题，极大地降低了程序出错的可能性和代码的复杂度。 语法简洁、易读易写：Go语言的语法简洁，没有像C++和Java那样繁琐的语法，特别是其强制规范化的代码风格更是方便了开发者对代码的理解和阅读。 静态类型系统：Go语言采用静态类型系统，可以在编译期检查出很多类型错误，避免了在运行时出现的错误。 良好的可移植性：Go语言的标准库支持多种操作系统和硬件平台，开发者可以轻松地将代码移植到不同的平台上。 开发效率高：Go语言的构建工具可以帮助开发者进行高效构建和测试。同时，Go语言的包管理工具go mod也是一个非常强大的工具，可以帮助开发者解决依赖管理和版本控制等问题。 命令 go build go build -o \u0026#34;***.exe\u0026#34; go run main.go go install 变量 package main import \u0026#34;fmt\u0026#34; // 匿名变量(就是一个下划线) -\u0026gt; _ : 匿名变量不占用命名空间，不会分配内存（Lua里叫哑元变量） func foo(i int, s string) (int, string) { return i, s } func main() { x, _ := foo(0, \u0026#34;zero\u0026#34;) _, y := foo(1, \u0026#34;one\u0026#34;) fmt.Println(x, y) var name string // 声明 var age int = 16 // 声明并赋值 // 类型推导 var s1 string = \u0026#34;string1\u0026#34; var s2 = \u0026#34;string2\u0026#34; // 上面可直接写成这样 // 简短变量声明，只能在函数中使用，不能在全局使用 s3 := \u0026#34;string3\u0026#34; // 上面的简写 fmt.Println(name, age, s1, s2, s3) } 注意事项：\n函数外每个语句必须以关键字开始（var、func、const等） := 不能用于函数外 _用于占位符，表示忽略值 函数内声明变量不使用，编译不能通过（似乎不同版本有不同的要求） 常量 常量是恒定不变的值，使用关键字const\npackage main // 单个声明 const pai = 3.1415926 // 批量声明 const ( statusOK = 200 notFound = 404 ) // 这种批量声明方式，没有赋值的常量默认和上面那个值一样 const ( n1 = 200 n2 n3 ) // iota: 常量计数器, iota将在const关键字出现时重置为0，const中每新增一行常量声明将使iota计数一次（iota可以理解成const语句块的行索引）。使用iota简化定义，在定义枚举时很有用 const ( n1 = iota // 0 n2 // 1 n3 // 2 n4 // 3 ) const ( a1 = iota // 0 a2 // 1 _ // 2 a3 // 3 ) const ( b1 = iota // 0 b2 = 100 // 100 b3 = iota // 2 b4 // 3 ) // 多个常量声明在一行 const ( c1, c2 = iota + 1, iota + 2 // d1:0+1, d2:0+2 c3, c4 = iota + 1, iota + 2 // d3:1+1, d4:1+2 ) // iota的应用，举个例子 const ( _ = iota KB = 1 \u0026lt;\u0026lt; (10 * iota) MB = 1 \u0026lt;\u0026lt; (10 * iota) GB = 1 \u0026lt;\u0026lt; (10 * iota) TB = 1 \u0026lt;\u0026lt; (10 * iota) PB = 1 \u0026lt;\u0026lt; (10 * iota) ) 基本数据类型 基本数据类型有整型、浮点型、布尔型、字符串、数组、切片、结构体、函数、map、通道等\n整型 int8、int16、int32、int64、uint8、uint16、uint32、uint64\n特殊整型：\n类型 描述 uinit 32位操作系统上就是uint32，64位操作系统上就是uint64 int 32位操作系统上就是int32，64位操作系统上就是int64 uintptr 无符号整型，用于存放一个指针 八进制\u0026amp;十六进制 Go语言中无法直接使用二进制，关于八进制和十六进制实例如下：\npackage main import \u0026#34;fmt\u0026#34; func main() { var num1 = 101 // 十进制 fmt.Printf(\u0026#34;%d\\n\u0026#34;, num1) // 输出十进制数 fmt.Printf(\u0026#34;%b\\n\u0026#34;, num1) // 输出二进制数 fmt.Printf(\u0026#34;%o\\n\u0026#34;, num1) // 输出八进制数 fmt.Printf(\u0026#34;%x\\n\u0026#34;, num1) // 输出十六进制数 fmt.Printf(\u0026#34;%T\\n\u0026#34;, num1) // 输出数据类型 var num2 = 077 // 八进制 var num3 = 0x123456789abcdef // 十六进制 // 强制声明int8类型 var num4 int8 = 100 fmt.Println(num2, num3, num4) } 浮点型 float32、float64\npackage main import \u0026#34;fmt\u0026#34; func main() { f1 := 1.2345 fmt.Printf(\u0026#34;%T\\n\u0026#34;, f1) // float64 默认go语言中小数都是float64 } 复数 complex128和complex64\n布尔型 Go语言中使用bool类型声明布尔型，只有true和false两个值\n注意事项：\n布尔型默认值是false 不允许将整型强转为布尔型 布尔型无法参与数值运算，也无法与其他类型进行转换 字符串 Go语言中字符串内部实现使用UTF-8编码，字符串的值为双引号的内容。\nGo语言单引号包裹的是字符。\npackage main import \u0026#34;fmt\u0026#34; func main() { s1 := \u0026#34;嘻嘻\u0026#34; s2 := \u0026#39;1\u0026#39; s3 := \u0026#39;a\u0026#39; s4 := \u0026#39;岳\u0026#39; // 字节：1字节 = 8Bit（8个二进制位） // 定义多行字符串，使用`` s5 := `床前明月光 疑是地上霜 举头望明月 低头思故乡 ` fmt.Print(s1, s2, s3, s4, s5) } 字符串操作 功能 方法 求长度 len（str） 拼接字符串 加号或者fmt.Sprintf() 分割 strings.Split 是否包含 strings.contains 前后缀判断 strings.HasPrefix/strings.HasSuffix 子串出现的位置 strings.Index()/strings.LastIndex() join操作 strings.Join(a []string, sep string) 字符 组成字符串的元素称为字符，Go语言字符有两种：\nuint8，或者叫byte类型，代表了ASCII码的一个字符 rune，代表一个UTF-8字符，当需要表示中文、日语或者其他复合字符时，就需要用到rune类型。rune类型实际上是一个int32 修改字符串 字符串是无法直接修改的，如果修改，可以转换成字符切片\npackage main import \u0026#34;fmt\u0026#34; func main() { s1 := \u0026#34;岳小杨超可爱\u0026#34; s2 := []rune(s1) s2[2] = \u0026#39;羊\u0026#39; fmt.Printf(string(s2)) // 将s2强制转换成string } 复合数据类型 数组 数组的长度是数组类型的一部分\npackage main import \u0026#34;fmt\u0026#34; func main() { var nums [3]int fmt.Println(nums) } 初始化 如果不初始化，默认元素为零值\npackage main import \u0026#34;fmt\u0026#34; func main() { // 方式一 var nums1 = [4]int{1, 2, 3, 4} // [1, 2, 3, 4] // 方式二 var nums2 = [...]int{1, 2, 3, 4} // [1, 2, 3, 4] // 方式三 var nums3 = [4]int{1, 2} // [1, 2, 0, 0] // 方式四 var nums4 = [4]int{0: 1, 3: 4} // [1, 0, 0, 4] fmt.Println(nums1, nums2, nums3, nums4) } 遍历 package main import \u0026#34;fmt\u0026#34; func main() { names := [...]string{\u0026#34;岳杨\u0026#34;, \u0026#34;幂律\u0026#34;, \u0026#34;GO语言\u0026#34;} // 方式一 for i := 0; i \u0026lt; len(names); i++ { fmt.Println(names[i]) } // 方式二 for i, v := range names { fmt.Println(i, v) } } 数组是值类型\npackage main import \u0026#34;fmt\u0026#34; func main() { // 证明数组是值类型 nums1 := [3]int{1, 2, 3} nums2 := nums1 nums2[0] = 100 fmt.Println(nums1, nums2) // [1, 2, 3] [100, 2, 3] } 切片 切片Slice是一个拥有相通类型元素的可变长度的序列\npackage main import \u0026#34;fmt\u0026#34; func main() { var nums1 []int var nums2 []int fmt.Println(nums1 == nil) // true fmt.Println(nums2 == nil) // true nums1 = []int{1, 2, 3} nums2 = []int{4, 5, 6, 7} fmt.Println(nums1 == nil) // false fmt.Println(nums2 == nil) // false } 长度和容量 package main import \u0026#34;fmt\u0026#34; func main() { nums1 := []int{1, 3, 5, 7} // 切片 nums2 := [7]int{0, 1, 2, 3, 4, 5, 6} // 数组 fmt.Printf(\u0026#34;%d %d\\n\u0026#34;, len(nums1), cap(nums1)) fmt.Printf(\u0026#34;%d %d\\n\u0026#34;, len(nums2), cap(nums2)) } 由数组得到切片 package main import \u0026#34;fmt\u0026#34; func main() { nums1 := [7]int{0, 1, 2, 3, 4, 5, 6} // 数组 nums2 := nums1[0:4] // [0, 1, 2, 3] // 数组得到切片，左闭右开 nums3 := nums1[1:] nums4 := nums1[:4] nums5 := nums1[:] fmt.Println(nums1, nums2, nums3, nums4, nums5) } 1、切片是引用类型，真正的数组都是保存在底层的数组里。\n2、一个nil的切片是没有底层数组的。\n3、判断切片为空应该判断len() == 0。\n4、nil的切片就算没有底层数组，也可以进行append操作，append会自动为nil切片创建空间。\nmake函数 package main import \u0026#34;fmt\u0026#34; func main() { nums1 := make([]int, 5, 10) // 参数：切片类型，长度，容量 fmt.Println(nums1) } append函数 package main import \u0026#34;fmt\u0026#34; func main() { nums1 := []int{1, 2, 3} nums1[3] = 4 // 错误写法，切片超过容量导致编译错误：索引越界 fmt.Println(nums1) // append函数 fmt.Printf(\u0026#34;%v %d %d\u0026#34;, nums1, len(nums1), cap(nums1)) // [1, 2, 3] len=3 cap=3 nums1 = append(nums1, 4) // 调用append函数必须用原来的切片变量接收返回值 fmt.Printf(\u0026#34;%v %d %d\u0026#34;, nums1, len(nums1), cap(nums1)) // [1, 2, 3, 4] len=4 cap=6 } 调用append函数必须用原来的切片变量接收返回值，底层涉及到数组的重新分配内存空间\nappend函数会为空切片创建内存空间，并且会对容量不够的切片进行扩容操作\nfmt包 package main import \u0026#34;fmt\u0026#34; func main() { var num = 100 fmt.Printf(\u0026#34;%T\\n\u0026#34;, num) fmt.Printf(\u0026#34;%v\\n\u0026#34;, num) fmt.Printf(\u0026#34;%b\\n\u0026#34;, num) fmt.Printf(\u0026#34;%d\\n\u0026#34;, num) fmt.Printf(\u0026#34;%o\\n\u0026#34;, num) fmt.Printf(\u0026#34;%x\\n\u0026#34;, num) var str = \u0026#34;String\u0026#34; fmt.Printf(\u0026#34;%s\\n\u0026#34;, str) fmt.Printf(\u0026#34;%v\\n\u0026#34;, num) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, num) } 流程控制 if package main import \u0026#34;fmt\u0026#34; func main() { expression := true // 经典用法 if expression { // 执行操作 } else { // 执行操作 } // 特殊用法 if age := 19; age \u0026gt; 18 { fmt.Printf(\u0026#34;青年\u0026#34;) } } for package main import \u0026#34;fmt\u0026#34; func main() { for i := 0; i \u0026lt; 10; i++ { // 执行操作 fmt.Println(i) if i \u0026lt; 3 { continue // 跳过for循环 } else if i \u0026lt; 6 { break // 跳出for循环 } goto breakLabel // 跳出到标签 } breakLabel: // 标签 fmt.Println(\u0026#34;跳出来了，嘻嘻\u0026#34;) } for range package main import \u0026#34;fmt\u0026#34; func main() { s := \u0026#34;yueyang\u0026#34; for i, c := range s { fmt.Printf(\u0026#34;%d, %c\\n\u0026#34;, i, c) } } switch package main func main() { str := \u0026#34;0\u0026#34; switch str { case \u0026#34;0\u0026#34;: // 操作 case \u0026#34;1\u0026#34;: // 操作 default: // 操作 } switch str = \u0026#34;1\u0026#34;; str { case \u0026#34;0\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;: // 操作 fallthrough // 向下穿透一个 case \u0026#34;3\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;5\u0026#34;: // 操作 default: // 操作 } } 运算符 \u0026amp;按位与\n|按位或\n^按位异或\n\u0026lt;\u0026lt;左移\n\u0026gt;\u0026gt;右移\n指针 取地址操作符\u0026amp;\n取值操作符*\n注意事项：\n引用类型变量不仅要声明还要分配内存空间 那么就引入了两个初始化方式new make\nnew函数 new函数不太常用\npackage main type T struct{} func new(T) *T // 接收一个类型，返回该类型的指针 make函数 make也是用于内存分配的，区别于new，make函数只作用于slice、map、chan类型的内存创建，由于这些类型本身就是引用类型，make返回的就是类型本身。\npackage main func make(t string, size ...int) string // 接收一个类型和容量大小，返回类型本身 make函数是不可替代的函数，slice、map、chan都需要make函数初始化才能进行操作。\nnew和make 两者都是用来创建内存的 new用于类型的内存分配，内存对应的值为类型的零值，返回的是指向类型的指针 make作用于slice、map、chan类型，返回类型本身 结构体 自定义类型 类型定义和类型别名\npackage main import \u0026#34;fmt\u0026#34; // NewInt 类型定义 type NewInt int // MyInt 类型别名 type MyInt = int func main() { var a NewInt var b MyInt fmt.Println(\u0026#34;%T\u0026#34;, a) // main.NewInt fmt.Println(\u0026#34;%T\u0026#34;, b) // int } 结构体 Go语言通过struct来面向对象\npackage main type T struct { Id int Name string } 结构体实例化 package main import \u0026#34;fmt\u0026#34; type Person struct { name string age int8 } func main() { var person Person person.name = \u0026#34;yueyang\u0026#34; person.age = 24 fmt.Printf(\u0026#34;%v\\n\u0026#34;, person) // {yueyang, 24} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, person) // main.Person{name:\u0026#34;yueyang\u0026#34;, age:24} } 匿名结构体 package main import \u0026#34;fmt\u0026#34; func main() { var user struct { Name string Age int } user.Name = \u0026#34;yueyang\u0026#34; user.Age = 24 fmt.Printf(\u0026#34;%#v\\n\u0026#34;, user) // struct { Name string; Age int }{Name:\u0026#34;yueyang\u0026#34;, Age:24} } 结构体指针 package main import \u0026#34;fmt\u0026#34; type Person struct{} func main() { var person = new(Person) fmt.Printf(\u0026#34;%+v\u0026#34;, *person) } 2、Golang标准库 strconv Atoi() 将字符串转换成整形\nItoa() 将整形转换成字符串\nParseBool() 解析字符串成布尔类型, 可以接受1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False; 否则返回错误\nParseInt() ParseUnit() 类似于ParseInt(), 区别在于不能接受正负号, 返回uint\nParseFloat() FormatBool() FormatInt() FormatUint() FormatFloat() 3、异常机制 go中追求简洁优雅，使用多返回值来返回错误解决异常情况。只有在除数为零时，才会真正的使用异常机制，defer、panic、recover\n底层实现看这篇文章\n调用 defer 关键字会立刻对函数中引用的外部参数进行拷贝\n4、Golang第三方包 github.com/gin-gonic/gin gin包提供golang一个基本web框架\ngin.Context实现了Golang标准库中的net/http下Handler接口中的唯一方法ServeHttp(ReponseWriter, *Request)\npackage http // A Handler responds to an HTTP request. // // ServeHTTP should write reply headers and data to the ResponseWriter // and then return. Returning signals that the request is finished; it // is not valid to use the ResponseWriter or read from the // Request.Body after or concurrently with the completion of the // ServeHTTP call. // // Depending on the HTTP client software, HTTP protocol version, and // any intermediaries between the client and the Go server, it may not // be possible to read from the Request.Body after writing to the // ResponseWriter. Cautious handlers should read the Request.Body // first, and then reply. // // Except for reading the body, handlers should not modify the // provided Request. // // If ServeHTTP panics, the server (the caller of ServeHTTP) assumes // that the effect of the panic was isolated to the active request. // It recovers the panic, logs a stack trace to the server error log, // and either closes the network connection or sends an HTTP/2 // RST_STREAM, depending on the HTTP protocol. To abort a handler so // the client sees an interrupted response but the server doesn\u0026#39;t log // an error, panic with the value ErrAbortHandler. type Handler interface { ServeHTTP(ResponseWriter, *Request) } type ResponseWriter struct { // ... } type Request struct { // ... } 这是 Golang 实现 WebService 最基础的接口，通过实现其方法来\nGolang 的编译过程 词法和语法分析：编译器读入源代码文件，对代码进行分词和语法分析，生成语法树的数据结构。 AST 转换：编译器会对语法树进行一些处理和转换，例如检查类型、解析函数调用等，在此过程中还会对代码进行优化。 代码生成：将转换后的语法树转换成机器码或字节码，并将其打包成可执行文件或库文件。 链接：链接器将被引用的库文件链接到目标程序中，生成最终的可执行文件。在 Golang 中，链接过程是由 go 工具自动完成的，开发人员无需显式执行链接命令。 ","permalink":"http://localhost:1313/posts/learn4go/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文目的是记录我从 Java 开发转 Golang 开发的学习经历，分享一下学习过程来帮助想要 Java 转 Golang 的朋友一起进步一起学习！\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Learn4go"},{"content":"前言 SQL优化一般遵循五个原则：\n减少数据访问 返回更少的数据：只返回需要的字段和数据分页处理，减少磁盘IO和网络IO 减少交互次数：批量DML操作，来减少与数据库的交互次数 减少服务器CPU开销：减少数据库排序操作以及全表查询，减少CPU内存占用 利用更多资源：使用表分区，增加并行操作，最大限度使用CPU资源 总结一下就是\n最大化利用索 尽可能避免全表扫描 减少无效数据的查询 SELECT语句——语法顺序 select distinct \u0026lt;查询字段\u0026gt; from \u0026lt;表名\u0026gt; left / right join \u0026lt;表名\u0026gt; on \u0026lt;条件\u0026gt; where \u0026lt;条件\u0026gt; group by \u0026lt;分组字段\u0026gt; having \u0026lt;分组条件\u0026gt; order by \u0026lt;排序字段\u0026gt; limit \u0026lt;参数1, 参数2\u0026gt; SELECT语句——执行顺序 from \u0026lt;表名\u0026gt; -- 选取表, 如果是多个表通过笛卡尔积形成一个表 on \u0026lt;条件\u0026gt; -- 对from的表进行筛选 join \u0026lt;表名\u0026gt; -- 添加字段到on之后的结果中 where \u0026lt;条件\u0026gt; -- 对结果再进行筛选 group by \u0026lt;分组字段\u0026gt; having \u0026lt;分组条件\u0026gt; -- 对分组之后的结果再进行筛选 select \u0026lt;字段\u0026gt; -- 筛选列, 返回的单列必须在group by中 distinct -- 数据去重 order by \u0026lt;排序字段\u0026gt; -- 排序 limit -- 行数限制 SQL优化策略 一、避免不走索引的场景 避免在字段开头模糊查询，会放弃索引而全表扫描\n-- 尽量避免 select id from user where name like \u0026#39;%岳%\u0026#39; -- 优化方式 select id from user where name like \u0026#39;岳%\u0026#39; -- 如果必须要在字段开头模糊查询, 建议使用以下策略: -- 1. 使用FullText全文检索 -- 2. 数据量较大时使用ElasticSearch -- 3. 使用MySQL内置函数INSTR(str,substr)来匹配 -- 4. 如果数据量少, 就不用花里胡哨的使用策略了, 直接%% 避免使用or，会放弃索引而全表扫描\n-- 不推荐 select id from user where name = \u0026#39;yueyang\u0026#39; or name = \u0026#39;mengwu\u0026#39; -- 推荐 select id from user where name = \u0026#39;yueyang\u0026#39; union all select id from user where name = \u0026#39;mengwu\u0026#39; 避免进行null值判断，会放弃索引而全表扫描\n-- 不推荐 select id from user where score is null -- 优化方式:给字段设置默认值 select id from user where score = 0 避免在where条件等号左侧使用表达式，会放弃索引而全表扫描\n-- 不推荐 select id from user where score/10 = 8 -- 优化方式:把左侧表达式的操作移到右侧 select id from user where score = 8 * 10 二、SELECT 语句优化 禁止出现select *，需要哪些字段必须明确标明， 原因是：\n增加了查询分析器解析成本 容易与resultMap配置不一致 无用字段增加了网络IO 多表关联查询时，小表在前，大表在后\n多表关联查询会全表扫描第一张表，所以第一张表尽可能小会提升不少性能\n使用表的别名\nSQL连接多个表时，使用表的别名并用表的别名来指定字段会减少解析时间\n三、DML 语句优化 批量insert数据使用insert多个值的方法\n-- 不推荐 insert into user (id, name, age) values (1, \u0026#39;yueyang\u0026#39;, 18); insert into user (id, name, age) values (2, \u0026#39;mengwu\u0026#39;, 19); -- 推荐 insert into user (id, name, age) values (1, \u0026#39;yueyang\u0026#39;, 18),(2, \u0026#39;mengwu\u0026#39;, 19); 四、查询条件优化 对于复杂查询，使用中间表暂存数据\n优化group by语句\n默认情况下, MySQL会对group by中所有的值进行排序，也就相当于在后面添加了一段order by\n因此，查询group by如果你不想对分组数据进行排序，可以在最后加上order by null\n优化join语句\n对于逻辑顺畅的子查询来说，有时使用join替代会有更好的效率\n-- 查询没有成绩的学生ID select id from user not in(select id from grade where score = 0); -- 优化方式:减少了内存创建临时表的损耗 select id from user left join grade on user.id = grade.id where grade.socre = 0; 优化union语句\nMySQL通过创建临时表并填充临时表的方式来执行union查询。\n使用union时，会隐式的给临时表加distinct ，从而对整个临时表做唯一性校验，非常损耗性能。因此如果不是非要去重，非常不建议使用union ，建议改成union all。\n合理的分页方式进行分页优化（^_^这个地方我还没学会呢，大家自己去研究深入一下，欢迎给我留言）\n五、建表优化 在表中建立索引，优先考虑where、order by使用到的字段。\n尽量使用数字型字段\n举个例子：性别男（1）女（2），就不要设计成字符型字段，会增加查询和连接性能，并增加存储开销\n六、事务优化 -- 查询事务执行的锁情况 select * from INFORMATION_SCHEMA.INNODB_TRX; 概念 MVCC: 多版本并发控制技术的英文全称是 Multiversion Concurrency Control，简称 MVCC。\n多版本并发控制（MVCC） 是通过保存数据在某个时间点的快照来实现并发控制的。也就是说，不管事务执行多长时间，事务内部看到的数据是不受其它事务影响的，根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。\n","permalink":"http://localhost:1313/posts/learn4mysql/","summary":"","title":"Learn4mysql"},{"content":" 整理Redis整体且全面的知识架构，一片文章了解Redis大部分基础应用\nRedis 1. NoSQL应用场景 数据模型比较简单\n需要灵活性更强的IT系统\n对数据库性能要求较高\n不需要高度的数据一致性\n2. 什么是Redis Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker.\nRedis 开源 遵循BSD 基于内存数据存储 被用于作为 数据库 缓存 消息中间件\n总结: redis是一个内存型的数据库 3. Redis特点 Redis是一个高性能key/value内存型数据库\nRedis支持丰富的数据类型\nRedis支持持久化\nRedis单线程,单进程\n4. Redis指令以及数据类型 4.1 数据库操作指令 # 1.Redis中库说明 - 使用redis的默认配置器动redis服务后,默认会存在16个库,编号从0-15 - 可以使用select 库的编号 来选择一个redis的库 # 2.Redis中操作库的指令 - 清空当前的库 FLUSHDB - 清空全部的库 FLUSHALL # 3.redis客户端显示中文 -\t./redis-cli -p 7000 --raw 4.2 操作key相关指令 # 1.DEL指令 - 语法 : DEL key [key ...] - 作用 : 删除给定的一个或多个key 。不存在的key 会被忽略。 - 可用版本： \u0026gt;= 1.0.0 - 返回值： 被删除key 的数量。 # 2.EXISTS指令 - 语法: EXISTS key - 作用: 检查给定key 是否存在。 - 可用版本： \u0026gt;= 1.0.0 - 返回值： 若key 存在，返回1 ，否则返回0。 # 3.EXPIRE - 语法: EXPIRE key seconds - 作用: 为给定key 设置生存时间，当key 过期时(生存时间为0 )，它会被自动删除。 - 可用版本： \u0026gt;= 1.0.0 - 时间复杂度： O(1) - 返回值：设置成功返回1 。 # 4.KEYS - 语法 : KEYS pattern - 作用 : 查找所有符合给定模式pattern 的key 。 - 语法: KEYS * 匹配数据库中所有key 。 KEYS h?llo 匹配hello ，hallo 和hxllo 等。 KEYS h*llo 匹配hllo 和heeeeello 等。 KEYS h[ae]llo 匹配hello 和hallo ，但不匹配hillo 。特殊符号用 \u0026#34;\\\u0026#34; 隔开 - 可用版本： \u0026gt;= 1.0.0 - 返回值： 符合给定模式的key 列表。 # 5.MOVE - 语法 : MOVE key db - 作用 : 将当前数据库的key 移动到给定的数据库db 当中。 - 可用版本： \u0026gt;= 1.0.0 - 返回值： 移动成功返回1 ，失败则返回0 。 # 6.PEXPIRE - 语法 : PEXPIRE key milliseconds - 作用 : 这个命令和EXPIRE 命令的作用类似，但是它以毫秒为单位设置key 的生存时间，而不像EXPIRE 命令那样，以秒为单位。 - 可用版本： \u0026gt;= 2.6.0 - 时间复杂度： O(1) - 返回值：设置成功，返回1 key 不存在或设置失败，返回0 # 7.PEXPIREAT - 语法 : PEXPIREAT key milliseconds-timestamp - 作用 : 这个命令和EXPIREAT 命令类似，但它以毫秒为单位设置key 的过期unix 时间戳，而不是像EXPIREAT那样，以秒为单位。 - 可用版本： \u0026gt;= 2.6.0 - 返回值：如果生存时间设置成功，返回1 。当key 不存在或没办法设置生存时间时，返回0 。(查看EXPIRE 命令获取更多信息) # 8.TTL - 语法 : TTL key - 作用 : 以秒为单位，返回给定key 的剩余生存时间(TTL, time to live)。 - 可用版本： \u0026gt;= 1.0.0 - 返回值： 当key 不存在时，返回-2 。 当key 存在但没有设置剩余生存时间时，返回-1 。 否则，以秒为单位，返回key 的剩余生存时间。 - Note : 在Redis 2.8 以前，当key 不存在，或者key 没有设置剩余生存时间时，命令都返回-1 。 # 9.PTTL - 语法 : PTTL key - 作用 : 这个命令类似于TTL 命令，但它以毫秒为单位返回key 的剩余生存时间，而不是像TTL 命令那样，以秒为单位。 - 可用版本： \u0026gt;= 2.6.0 - 返回值： 当key 不存在时，返回-2 。当key 存在但没有设置剩余生存时间时，返回-1 。 - 否则，以毫秒为单位，返回key 的剩余生存时间。 - 注意 : 在Redis 2.8 以前，当key 不存在，或者key 没有设置剩余生存时间时，命令都返回-1 。 # 10.RANDOMKEY - 语法 : RANDOMKEY - 作用 : 从当前数据库中随机返回(不删除) 一个key 。 - 可用版本： \u0026gt;= 1.0.0 - 返回值：当数据库不为空时，返回一个key 。当数据库为空时，返回nil 。 # 11.RENAME - 语法 : RENAME key newkey - 作用 : 将key 改名为newkey 。当key 和newkey 相同，或者key 不存在时，返回一个错误。当newkey 已经存在时，RENAME 命令将覆盖旧值。 - 可用版本： \u0026gt;= 1.0.0 - 返回值： 改名成功时提示OK ，失败时候返回一个错误。 # 12.TYPE - 语法 : TYPE key - 作用 : 返回key 所储存的值的类型。 - 可用版本： \u0026gt;= 1.0.0 - 返回值： none (key 不存在) string (字符串) list (列表) set (集合) zset (有序集) hash (哈希表) 4.3 String类型 1. 内存存储模型 朴实无华的String类型\n2. 常用操作命令 命令 说明 set 设置一个key/value get 根据key获得对应的value mset 一次设置多个key value mget 一次获得多个key的value getset 获得原始key的值，同时设置新值 strlen 获得对应key存储value的长度 append 为对应key的value追加内容 getrange 索引0开始 截取value的内容 setex 设置一个key存活的有效期（秒） psetex 设置一个key存活的有效期（毫秒） setnx 存在不做任何操作,不存在添加 msetnx原子操作(只要有一个存在不做任何操作) 可以同时设置多个key,只有有一个存在都不保存 decr 进行数值类型的-1操作 decrby 根据提供的数据进行减法操作 Incr 进行数值类型的+1操作 incrby 根据提供的数据进行加法操作 Incrbyfloat 根据提供的数据加入浮点数 4.4 List类型 list 列表 相当于java中list 集合 特点 元素有序 且 可以重复\n1.内存存储模型 是左右端都可以操作的双向链表\n2.常用操作指令 命令 说明 lpush 将某个值加入到一个key列表头部 lpushx 同lpush,但是必须要保证这个key存在 rpush 将某个值加入到一个key列表末尾 rpushx 同rpush,但是必须要保证这个key存在 lpop 返回和移除列表左边的第一个元素 rpop 返回和移除列表右边的第一个元素 lrange 获取某一个下标区间内的元素 llen 获取列表元素个数 lset 设置某一个指定索引的值(索引必须存在) lindex 获取某一个指定索引位置的元素 lrem 删除重复元素 ltrim 保留列表中特定区间内的元素 linsert 在某一个元素之前，之后插入新元素 4.5 Set类型 特点: Set类型 Set集合 元素无序 不可以重复\n1.内存存储模型 朴实无华的Set类型\n2.常用命令 命令 说明 sadd 为集合添加元素 smembers 显示集合中所有元素 无序 scard 返回集合中元素的个数 spop 随机返回一个元素 并将元素在集合中删除 smove 从一个集合中向另一个集合移动元素 必须是同一种类型 srem 从集合中删除一个元素 sismember 判断一个集合中是否含有这个元素 srandmember 随机返回元素 sdiff 去掉第一个集合中其它集合含有的相同元素 sinter 求交集 sunion 求和集 4.6 ZSet类型 特点: 可排序的set集合 排序 不可重复\nZSET 官方 可排序SET sortSet\n1.内存模型 朴实无华的ZSet集合\n2.常用命令 命令 说明 zadd 添加一个有序集合元素 zcard 返回集合的元素个数 zrange 升序 zrevrange 降序 返回一个范围内的元素 zrangebyscore 按照分数查找一个范围内的元素 zrank 返回排名 zrevrank 倒序排名 zscore 显示某一个元素的分数 zrem 移除某一个元素 zincrby 给某个特定元素加分 4.7 hash类型 特点: value 是一个map结构 存在key value key 无序的\n1.内存模型 朴实无华的HashMap\n2.常用命令 命令 说明 hset 设置一个key/value对 hget 获得一个key对应的value hgetall 获得所有的key/value对 hdel 删除某一个key/value对 hexists 判断一个key是否存在 hkeys 获得所有的key hvals 获得所有的value hmset 设置多个key/value hmget 获得多个key的value hsetnx 设置一个不存在的key的值 hincrby 为value进行加法运算 hincrbyfloat 为value加入浮点值 5. 持久化机制 client redis[内存] \u0026mdash;\u0026ndash;\u0026gt; 内存数据- 数据持久化\u0026ndash;\u0026gt;磁盘\nRedis官方提供了两种不同的持久化方法来将数据存储到硬盘里面分别是:\n快照(Snapshot) AOF (Append Only File) 只追加日志文件 5.1 快照(Snapshot) 1. 特点 这种方式可以将某一时刻的所有数据都写入硬盘中,当然这也是redis的默认开启持久化方式,保存的文件是以.rdb形式结尾的文件因此这种方式也称之为RDB方式。\n2.快照生成方式 客户端方式: BGSAVE 和 SAVE指令 服务器配置自动触发 # 1.客户端方式之BGSAVE - a.客户端可以使用BGSAVE命令来创建一个快照,当接收到客户端的BGSAVE命令时,redis会调用fork¹来创建一个子进程,然后子进程负责将快照写入磁盘中,而父进程则继续处理命令请求。 `名词解释: fork当一个进程创建子进程的时候,底层的操作系统会创建该进程的一个副本,在类unix系统中创建子进程的操作会进行优化:在刚开始的时候,父子进程共享相同内存,直到父进程或子进程对内存进行了写之后,对被写入的内存的共享才会结束服务` # 2.客户端方式之SAVE - b.客户端还可以使用SAVE命令来创建一个快照,接收到SAVE命令的redis服务器在快照创建完毕之前将不再响应任何其他的命令 注意: SAVE命令并不常用,使用SAVE命令在快照创建完毕之前,redis处于阻塞状态,无法对外服务 # 3.服务器配置方式之满足配置自动触发 - 如果用户在redis.conf中设置了save配置选项,redis会在save选项条件满足之后自动触发一次BGSAVE命令,如果设置多个save配置选项,当任意一个save配置选项条件满足,redis也会触发一次BGSAVE命令 # 4.服务器接收客户端shutdown指令 - 当redis通过shutdown指令接收到关闭服务器的请求时,会执行一个save命令,阻塞所有的客户端,不再执行客户端执行发送的任何命令,并且在save命令执行完毕之后关闭服务器 3.配置生成快照名称和位置 #1.修改生成快照名称 - dbfilename dump.rdb # 2.修改生成位置 - dir ./ 5.2 AOF 只追加日志文件 1.特点 这种方式可以将所有客户端执行的写命令记录到日志文件中,AOF持久化会将被执行的写命令写到AOF的文件末尾,以此来记录数据发生的变化,因此只要redis从头到尾执行一次AOF文件所包含的所有写命令,就可以恢复AOF文件的记录的数据集.\n2.开启AOF持久化 在redis的默认配置中AOF持久化机制是没有开启的，需要在配置中开启\n# 1.开启AOF持久化 - a.修改 appendonly yes 开启持久化 - b.修改 appendfilename \u0026#34;appendonly.aof\u0026#34; 指定生成文件名称 3.日志追加频率 # 1.always 【谨慎使用】 - 说明: 每个redis写命令都要同步写入硬盘,严重降低redis速度 - 解释: 如果用户使用了always选项,那么每个redis写命令都会被写入硬盘,从而将发生系统崩溃时出现的数据丢失减到最少;遗憾的是,因为这种同步策略需要对硬盘进行大量的写入操作,所以redis处理命令的速度会受到硬盘性能的限制; - 注意: 转盘式硬盘在这种频率下200左右个命令/s ; 固态硬盘(SSD) 几百万个命令/s; - 警告: 使用SSD用户请谨慎使用always选项,这种模式不断写入少量数据的做法有可能会引发严重的写入放大问题,导致将固态硬盘的寿命从原来的几年降低为几个月。 # 2.everysec 【推荐】 - 说明: 每秒执行一次同步显式的将多个写命令同步到磁盘 - 解释： 为了兼顾数据安全和写入性能,用户可以考虑使用everysec选项,让redis每秒一次的频率对AOF文件进行同步;redis每秒同步一次AOF文件时性能和不使用任何持久化特性时的性能相差无几,而通过每秒同步一次AOF文件,redis可以保证,即使系统崩溃,用户最多丢失一秒之内产生的数据。 # 3.no\t【不推荐】 - 说明: 由操作系统决定何时同步 - 解释：最后使用no选项,将完全有操作系统决定什么时候同步AOF日志文件,这个选项不会对redis性能带来影响但是系统崩溃时,会丢失不定数量的数据,另外如果用户硬盘处理写入操作不够快的话,当缓冲区被等待写入硬盘数据填满时,redis会处于阻塞状态,并导致redis的处理命令请求的速度变慢。 4.修改同步频率 # 1.修改日志同步频率 - 修改appendfsync everysec|always|no 指定 5.3 AOF文件的重写 1. AOF带来的问题 AOF的方式也同时带来了另一个问题。持久化文件会变的越来越大。例如我们调用incr test命令100次，文件中必须保存全部的100条命令，其实有99条都是多余的。因为要恢复数据库的状态其实文件中保存一条set test 100就够了。为了压缩aof的持久化文件Redis提供了AOF重写(ReWriter)机制。\n2. AOF重写 用来在一定程度上减小AOF文件的体积\n3. 触发重写方式 # 1.客户端方式触发重写 - 执行BGREWRITEAOF命令 不会阻塞redis的服务 # 2.服务器配置方式自动触发 - 配置redis.conf中的auto-aof-rewrite-percentage选项 参加下图↓↓↓ - 如果设置auto-aof-rewrite-percentage值为100和auto-aof-rewrite-min-size 64mb,并且启用的AOF持久化时,那么当AOF文件体积大于64M,并且AOF文件的体积比上一次重写之后体积大了至少一倍(100%)时,会自动触发,如果重写过于频繁,用户可以考虑将auto-aof-rewrite-percentage设置为更大 4. 重写原理 注意：重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件,替换原有的文件这点和快照有点类似。\n# 重写流程 - 1. redis调用fork ，现在有父子两个进程 子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令 - 2. 父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。 - 3. 当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。 - 4. 现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。 5.4 持久化总结 两种持久化方案既可以同时使用(aof),又可以单独使用,在某种情况下也可以都不使用,具体使用那种持久化方案取决于用户的数据和应用决定。\n无论使用AOF还是快照机制持久化,将数据持久化到硬盘都是有必要的,除了持久化外,用户还应该对持久化的文件进行备份(最好备份在多个不同地方)。\n6. SpringBoot整合Redis Spring Boot Data(数据) Redis 中提供了RedisTemplate和StringRedisTemplate，其中StringRedisTemplate是RedisTemplate的子类，两个方法基本一致，不同之处主要体现在操作的数据类型不同，RedisTemplate中的两个泛型都是Object，意味着存储的key和value都可以是一个对象，而StringRedisTemplate的两个泛型都是String，意味着StringRedisTemplate的key和value都只能是字符串。\n注意: 使用RedisTemplate默认是将对象序列化到Redis中,所以放入的对象必须实现对象序列化接口\n11.1 环境准备 1.引入依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2.配置application.propertie spring.redis.host=localhost spring.redis.port=6379 spring.redis.database=0 11.2 使用StringRedisTemplate和RedisTemplate @Autowired private StringRedisTemplate stringRedisTemplate; //对字符串支持比较友好,不能存储对象 @Autowired private RedisTemplate redisTemplate; //存储对象 @Test public void testRedisTemplate(){ System.out.println(redisTemplate); //设置redistemplate值使用对象序列化策略 redisTemplate.setValueSerializer(new JdkSerializationRedisSerializer());//指定值使用对象序列化 //redisTemplate.opsForValue().set(\u0026#34;user\u0026#34;,new User(\u0026#34;21\u0026#34;,\u0026#34;小黑\u0026#34;,23,new Date())); User user = (User) redisTemplate.opsForValue().get(\u0026#34;user\u0026#34;); System.out.println(user); // Set keys = redisTemplate.keys(\u0026#34;*\u0026#34;); // keys.forEach(key -\u0026gt; System.out.println(key)); /*Object name = redisTemplate.opsForValue().get(\u0026#34;name\u0026#34;); System.out.println(name);*/ //Object xiaohei = redisTemplate.opsForValue().get(\u0026#34;xiaohei\u0026#34;); //System.out.println(xiaohei); /*redisTemplate.opsForValue().set(\u0026#34;name\u0026#34;,\u0026#34;xxxx\u0026#34;); Object name = redisTemplate.opsForValue().get(\u0026#34;name\u0026#34;); System.out.println(name);*/ /*redisTemplate.opsForList().leftPushAll(\u0026#34;lists\u0026#34;,\u0026#34;xxxx\u0026#34;,\u0026#34;1111\u0026#34;); List lists = redisTemplate.opsForList().range(\u0026#34;lists\u0026#34;, 0, -1); lists.forEach(list-\u0026gt; System.out.println(list));*/ } //key的绑定操作 如果日后对某一个key的操作及其频繁,可以将这个key绑定到对应redistemplate中,日后基于绑定操作都是操作这个key //boundValueOps 用来对String值绑定key //boundListOps 用来对List值绑定key //boundSetOps 用来对Set值绑定key //boundZsetOps 用来对Zset值绑定key //boundHashOps 用来对Hash值绑定key @Test public void testBoundKey(){ BoundValueOperations\u0026lt;String, String\u0026gt; nameValueOperations = stringRedisTemplate.boundValueOps(\u0026#34;name\u0026#34;); nameValueOperations.set(\u0026#34;1\u0026#34;); //yuew nameValueOperations.set(\u0026#34;2\u0026#34;); String s = nameValueOperations.get(); System.out.println(s); } //hash相关操作 opsForHash @Test public void testHash(){ stringRedisTemplate.opsForHash().put(\u0026#34;maps\u0026#34;,\u0026#34;name\u0026#34;,\u0026#34;小黑\u0026#34;); Object o = stringRedisTemplate.opsForHash().get(\u0026#34;maps\u0026#34;, \u0026#34;name\u0026#34;); System.out.println(o); } //zset相关操作 opsForZSet @Test public void testZSet(){ stringRedisTemplate.opsForZSet().add(\u0026#34;zsets\u0026#34;,\u0026#34;小黑\u0026#34;,10); Set\u0026lt;String\u0026gt; zsets = stringRedisTemplate.opsForZSet().range(\u0026#34;zsets\u0026#34;, 0, -1); zsets.forEach(value-\u0026gt; System.out.println(value)); } //set相关操作 opsForSet @Test public void testSet(){ stringRedisTemplate.opsForSet().add(\u0026#34;sets\u0026#34;,\u0026#34;xiaosan\u0026#34;,\u0026#34;xiaosi\u0026#34;,\u0026#34;xiaowu\u0026#34;); Set\u0026lt;String\u0026gt; sets = stringRedisTemplate.opsForSet().members(\u0026#34;sets\u0026#34;); sets.forEach(value-\u0026gt; System.out.println(value)); } //list相关的操作opsForList @Test public void testList(){ // stringRedisTemplate.opsForList().leftPushAll(\u0026#34;lists\u0026#34;,\u0026#34;张三\u0026#34;,\u0026#34;李四\u0026#34;,\u0026#34;王五\u0026#34;); List\u0026lt;String\u0026gt; lists = stringRedisTemplate.opsForList().range(\u0026#34;lists\u0026#34;, 0, -1); lists.forEach(key -\u0026gt; System.out.println(key)); } //String相关的操作 opsForValue @Test public void testString(){ //stringRedisTemplate.opsForValue().set(\u0026#34;166\u0026#34;,\u0026#34;好同学\u0026#34;); String s = stringRedisTemplate.opsForValue().get(\u0026#34;166\u0026#34;); System.out.println(s); Long size = stringRedisTemplate.opsForValue().size(\u0026#34;166\u0026#34;); System.out.println(size); } //key相关的操作 @Test public void test(){ Set\u0026lt;String\u0026gt; keys = stringRedisTemplate.keys(\u0026#34;*\u0026#34;);//查看所有key Boolean name = stringRedisTemplate.hasKey(\u0026#34;name\u0026#34;);//判断某个key是否存在 stringRedisTemplate.delete(\u0026#34;age\u0026#34;);//根据指定key删除 stringRedisTemplate.rename(\u0026#34;\u0026#34;,\u0026#34;\u0026#34;);//修改key的名称 stringRedisTemplate.expire(\u0026#34;key\u0026#34;,10, TimeUnit.HOURS); //设置key超时时间 参数1:设置key名 参数2:时间 参数3:时间的单位 stringRedisTemplate.move(\u0026#34;\u0026#34;,1);//移动key } 7. Redis 主从复制 7.1 主从复制 主从复制架构仅仅用来解决数据的冗余备份,从节点仅仅用来同步数据\n无法解决: 1.master节点出现故障的自动故障转移\n7.2 搭建主从复制 # 1.准备3台机器并修改配置 - master port 6379 bind 0.0.0.0 - slave1 port 6380 bind 0.0.0.0 slaveof masterip masterport - slave2 port 6381 bind 0.0.0.0 slaveof masterip masterport # 2.启动3台机器进行测试 - cd /usr/redis/bin - ./redis-server /root/master/redis.conf - ./redis-server /root/slave1/redis.conf - ./redis-server /root/slave2/redis.conf 8. Redis哨兵机制 8.1 哨兵Sentinel机制 Sentinel（哨兵）是Redis 的高可用性解决方案：由一个或多个Sentinel 实例 组成的Sentinel 系统可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器。简单的说哨兵就是带有自动故障转移功能的主从架构。\n无法解决: 1.单节点并发压力问题 2.单节点内存和磁盘物理上限\n8.2 搭建哨兵架构 # 1.在主节点上创建哨兵配置 - 在Master对应redis.conf同目录下新建sentinel.conf文件，名字绝对不能错； # 2.配置哨兵，在sentinel.conf文件中填入内容： - sentinel monitor 被监控数据库名字（自己起名字） ip port 1 # 3.启动哨兵模式进行测试 - redis-sentinel /root/sentinel/sentinel.conf 说明:这个后面的数字2,是指当有两个及以上的sentinel服务检测到master宕机，才会去执行主从切换的功能。 8.3 通过springboot操作哨兵 # redis sentinel 配置 # master书写是使用哨兵监听的那个名称 spring.redis.sentinel.master=mymaster # 连接的不再是一个具体redis主机,书写的是多个哨兵节点 spring.redis.sentinel.nodes=192.168.202.206:26379 注意:如果连接过程中出现如下错误:RedisConnectionException: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command \u0026lsquo;CONFIG SET protected-mode no\u0026rsquo; from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) 解决方案:在哨兵的配置文件中加入bind 0.0.0.0 开启远程连接权限 9. Redis集群 9.1 集群 Redis在3.0后开始支持Cluster(模式)模式,目前redis的集群支持节点的自动发现,支持slave-master选举和容错,支持在线分片(sharding shard )等特性。reshard\n9.2 集群细节 - 所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽. - 节点的fail是通过集群中超过半数的节点检测失效时才生效. - 客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可 - redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护node\u0026lt;-\u0026gt;slot\u0026lt;-\u0026gt;value 9.3 集群搭建 判断一个是集群中的节点是否可用,是集群中的所用主节点选举过程,如果半数以上的节点认为当前节点挂掉,那么当前节点就是挂掉了,所以搭建redis集群时建议节点数最好为奇数，搭建集群至少需要三个主节点,三个从节点,至少需要6个节点。\n# 1.准备环境安装ruby以及redis集群依赖 - yum install -y ruby rubygems - gem install redis-xxx.gem # 2.在一台机器创建7个目录 # 3.每个目录复制一份配置文件 [root@localhost ~]# cp redis-4.0.10/redis.conf 7000/ [root@localhost ~]# cp redis-4.0.10/redis.conf 7001/ [root@localhost ~]# cp redis-4.0.10/redis.conf 7002/ [root@localhost ~]# cp redis-4.0.10/redis.conf 7003/ [root@localhost ~]# cp redis-4.0.10/redis.conf 7004/ [root@localhost ~]# cp redis-4.0.10/redis.conf 7005/ [root@localhost ~]# cp redis-4.0.10/redis.conf 7006/ # 4.修改不同目录配置文件 - port 6379 ..... //修改端口 - bind 0.0.0.0 //开启远程连接 - cluster-enabled yes //开启集群模式 - cluster-config-file nodes-port.conf //集群节点配置文件 - cluster-node-timeout 5000 //集群节点超时时间 - appendonly yes //开启AOF持久化 # 5.指定不同目录配置文件启动七个节点 - [root@localhost bin]# ./redis-server /root/7000/redis.conf - [root@localhost bin]# ./redis-server /root/7001/redis.conf - [root@localhost bin]# ./redis-server /root/7002/redis.conf - [root@localhost bin]# ./redis-server /root/7003/redis.conf - [root@localhost bin]# ./redis-server /root/7004/redis.conf - [root@localhost bin]# ./redis-server /root/7005/redis.conf - [root@localhost bin]# ./redis-server /root/7006/redis.conf # 6.查看进程 - [root@localhost bin]# ps aux|grep redis 1.创建集群 # 1.复制集群操作脚本到bin目录中 - [root@localhost bin]# cp /root/redis-4.0.10/src/redis-trib.rb . # 2.创建集群 - ./redis-trib.rb create --replicas 1 192.168.202.205:7000 192.168.202.205:7001 192.168.202.205:7002 192.168.202.205:7003 192.168.202.205:7004 192.168.202.205:7005 # 3.集群创建成功 2.查看集群状态 # 1.查看集群状态 check [原始集群中任意节点] [无] - ./redis-trib.rb check 192.168.202.205:7000 # 2.集群节点状态说明 - 主节点 主节点存在hash slots,且主节点的hash slots 没有交叉 主节点不能删除 一个主节点可以有多个从节点 主节点宕机时多个副本之间自动选举主节点 - 从节点 从节点没有hash slots 从节点可以删除 从节点不负责数据的写,只负责数据的同步 3.添加主节点 # 1.添加主节点 add-node [新加入节点] [原始集群中任意节点] - ./redis-trib.rb add-node 192.168.1.158:7006 192.168.1.158:7005 - 注意: 1.该节点必须以集群模式启动 2.默认情况下该节点就是以master节点形式添加 4.添加从节点 # 1.添加从节点 add-node --slave [新加入节点] [集群中任意节点] - ./redis-trib.rb add-node --slave 192.168.1.158:7006 192.168.1.158:7000 - 注意: 当添加副本节点时没有指定主节点,redis会随机给副本节点较少的主节点添加当前副本节点 # 2.为确定的master节点添加主节点 add-node --slave --master-id master节点id [新加入节点] [集群任意节点] - ./redis-trib.rb add-node --slave --master-id 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7006 127.0.0.1:7000 5.删除副本节点 # 1.删除节点 del-node [集群中任意节点] [删除节点id] - ./redis-trib.rb del-node 127.0.0.1:7002 0ca3f102ecf0c888fc7a7ce43a13e9be9f6d3dd1 - 注意: 1.被删除的节点必须是从节点或没有被分配hash slots的节点 6.集群在线分片 # 1.在线分片 reshard [集群中任意节点] [无] - ./redis-trib.rb reshard 192.168.1.158:7000 10.Redis实现分布式Session管理 10.1 管理机制 redis的session管理是利用spring提供的session管理解决方案,将一个应用session交给Redis存储,整个应用中所有session的请求都会去redis中获取对应的session数据。\n10.2 开发Session管理 1. 引入依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.session\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-session-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2. 开发Session管理配置类 @Configuration @EnableRedisHttpSession public class RedisSessionManager { } 3.打包测试即可 11.总结面试 11.1缓存穿透、缓存击穿、缓存雪崩以及解决方案？ 缓存穿透：请求查询的ID是缓存和数据库中都不存在的，外部攻击频繁查询不存在的ID而不经过缓存，导致频繁查询数据库，而对数据库的压力过大。\n解决方案：\n对查询ID进行校验，不符合的ID被拦截。 对缓存和数据库中都不取不到的ID进行缓存，key-value设置为key-null，缓存的有效时间设置短点。 缓存击穿：请求查询的ID是缓存中不存在，而数据库中存在的，情景理解成一个缓存在刚好失效的时候，大量的请求涌入，由于缓存不存在而去大量访问数据库，导致对数据库的压力过大。\n解决方案：\n设置键永久期限（不推荐） 互斥锁：Redis使用SETNX（set if not exists） 布隆过滤器 缓存雪崩：多个请求查询的ID是缓存中不存在而数据库中存在,大量缓存设置了相同的生存时间后同时失效,高并发情况下大量的数据同时涌入数据库,导致数据库压力瞬间过大而挂起\n解决方案：\n根据业务场景给不同的key设置不同的过期时间 设置键的永久期限（不推荐） 11.2Redis为什么这么快? 完全基于内存操作 C语言编写，使用优化过的基本数据结构 单线程，无上下文切换成本 NIO：非阻塞的IO多路复用 11.3那为什么Redis6.0之后又改成了多线程？ # Redis使用多线程并非摒弃单线程，Redis的多线程只是在处理数据的读写和协议解析的时候使用，在执行命令时还是使用单线程。 # 目的是Redis的性能瓶颈是网络IO而非CPU，使用多线程来处理IO读写效率从而提升整体Redis效率。 11.4Redis的热key问题是什么？怎么解决热key问题？ # 所谓热key问题，就是一瞬间大量热点数据访问redis中某个key，瞬间达到物理网卡上限，导致Redis宕机。 # 解决热key问题可以将热点key加入二级缓存，如果Redis宕机，直接从内存中读取。 11.5持久化方式有那些？ RDB\n内存快照\nAOF\n日志追加\n11.6Redis如何实现高可用？ # 主从复制架构 # 主从复制架构是最简单实现高可用的方案，核心就是主从同步。主从同步的原理： 1. slave发送sync命令到master 2. master收到sync之后，执行bgsave，生成RDB全量文件 3. master把slave的写命令记录到缓存 4. bgsave执行完毕之后，发送RDB文件到slave，slave执行 5. master发送缓存中的写命令到slave，slave执行 # 哨兵模式 # 哨兵模式解决了主从复制无法实现的自动故障转移、集群监控、消息通知。 11.7Redis集群的原理是什么？ # Redis集群 # Redis集群是Redis提供的分布式存储方案，利用分片sharding来对数据进行共享，同时还提供自动故障转移和复制功能。 # 节点 # 一个Redis集群由多个节点构成，节点之间通过cluster meet命令进行链接。连接的握手过程： 1. 节点A收到客户端的cluster meet命令 2. 节点A根据接收到的IP和PORT向节点B发送meet消息 3. 节点B收到meet消息返回ping给节点A 4. 节点A收到ping消息返回pong给节点B，握手成功 5. 节点A通过gossip协议把节点B的信息传播给集群中其他节点，其他节点和节点B进行握手 - 补充： 发送meet消息是加入节点是发生的，发送ping-pong是每个节点每隔一秒就会从已知节点中随机选出5个节点，然后对这5个节点中最久没有发送过ping消息的节点发送ping，以此来检验被选中节点是否在线。 # Slot 槽 # 节点分为主节点、从节点，一个Reids集群中有16384个Slot槽，会均匀的分配到所有集群主节点中，读取数据时key进行哈希计算得到一个slot对应的值。主节点宕机从节点会接替主节点的所有slot槽。 # 故障转移 # 如果节点B在被ping后没有相应pong，那么节点A会标记节点B为fail状态，超过半数节点标记节点B为fail状态，则节点B为宕机状态，节点B下的备份数据最多的将替代节点B，接收节点B的所有slot槽。整个过程和哨兵非常类似，都是基于Raft协议做选举。 11.8了解Redis事务吗？ 使用MULT、EXEC、WATCH命令来实现事务，事务的执行过程是多个命令按照顺序一次性执行完成，并在执行期间事务不会被中断，如果遇到其他正在执行的事务，会返回QUEUED。\n","permalink":"http://localhost:1313/posts/learn4redis/","summary":"\u003cblockquote\u003e\n\u003cp\u003e整理Redis整体且全面的知识架构，一片文章了解Redis大部分基础应用\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Learn4redis"},{"content":" 日常使用Git操作，随笔整理持续更新\n基本操作 初始化仓库 git init -- 在当前目录下初始化一个git仓库, 如果是基本项目开发基本用不到这个命令 克隆代码 git colne \u0026lt;url\u0026gt; 添加工作区文件到暂存区 git add \u0026lt;fileName\u0026gt; -- 指定一个文件添加到暂存区 git add . -- 常用, 将当前目录下的所有改动的文件添加到暂存区 工作区：项目目录下除了.git文件夹以外的区域，简单来说就是你的项目文件区域\n查看工作状态 git status -- 查看当前工作区和暂存区的文件状态 提交暂存区文件到本地仓库 git commit -m \u0026#34;本次提交的描述内容\u0026#34; 版本回退 git reset [--soft | --mixed | --hard ] [HEAD]-- 将暂存区的文件取消暂存 --mixed为默认参数，重置暂存区的文件与上一次提交保持一致，工作区内容不变。可以理解成把工作区的文件和上次一提交的文件重新比对。效果上就像把暂存区的文件重新拿到工作区。\n--soft为回退到上一个版本。\n--hard为撤销工作区中所有未提交的内容，将暂存区和工作区都回到上一次版本，并删除之前的所有信息。就把这个参数理解成回到某个版本\u0026quot;最初的样子\u0026quot;。效果上就像时间回溯到了上一个版本提交之前，重新开发上一个版本一样。\n其实git reset操作用好了还是挺有用的，比如你当前项目改了一堆没用的地方，你都不想要了，就可以：\ngit reset --hard HEAR将当前工作区和暂存区恢复成当前版本\u0026quot;最初的样子\u0026quot;，本地代码瞬间全没了！妙~~~啊！(\\狗头)\n拉取代码 git pull 推送本地仓库到远程仓库 git push \u0026lt;远程主机名\u0026gt; \u0026lt;本地分支名\u0026gt;:\u0026lt;远程分支名\u0026gt; -- 最原始的命令 git push -- 常用, 将当前分支推送到远程绑定的对应分支 更新远端分支 git remote update origin -p 分支操作 查看本地所有分支 git branch -a -- 展示的列表中*符号说明当前代码处于哪个分支 有时候远端的分支刷新了，你本地获取分支列表发现，\u0026ldquo;啊哈，分支列表和远端对应不上！\u0026quot;。这时候不用慌，是因为这个列表是保存在本地的，并不是从远端实时获取的，你需要做的就是刷新这个保存在本地的列表与远端同步：\ngit remote update origin -p -- 用远端来更新本地仓库 创建分支 git branch \u0026lt;name\u0026gt; -- 从当前分支创建了名称为 dev 的分支 切换分支 git checkout \u0026lt;branchName\u0026gt; -- 切换到本地目标分支 git checkout -b \u0026lt;newBranchName\u0026gt; -- 从当前分支创建一个新分支并切换到新分支上 git checkout -b操作可以在任一分支的任何状态执行，执行成功之后，会将所有操作复制到新的分支上，并且会切换到新分支，如果新分支提交了修改，则原有分支的操作会撤销掉。\n合并某分支到当前分支 git merge \u0026lt;branchName\u0026gt; -- 合并目标分支到当前分支 删除本地分支 git branch -d \u0026lt;branchName\u0026gt; -- 删除本地的目标分支 重新定基操作 git rebase \u0026lt;branchName\u0026gt; -- 以本地目标分支为基准，合并代码 首先，说明一下rebase的作用：将目标分支的开发呈现一条直线，没有其他分支合并进来的节点，展示起来比较清晰。\n那么能来点实际吗？——彳亍\ngit rebase相关流程\ngit checkout -b [本地开发分支名] origin/[远程分支名] -- 以目标分支为基准创建新分支并关联远端分支 ....... -- 修改代码的操作 git add . -- 添加所有本次修改的文件添加到暂存区 git commit -m \u0026#34;注释内容\u0026#34; -- 提交代码，保存本地分支 git checkout [主分支] -- 切换分支，这个分支是目标基点的分支，简单来说，就是把现在的代码变成从\u0026#34;这个分支开始进行开发\u0026#34;的分支 git pull -- 拉取主分支代码，此时本地仓库主分支代码为最新代码，本地开发分支有所有修改的代码 git checkout [本地开发分支] // 切回本地开发分支，准备rebase git rebase [主分支] -i HEAD~2 // 将当前分支合并提交到目标分支 // rebase过程可能会出现冲突，解决冲突后继续rebase过程 git rebase [主分支] --continue // 继续rebase过程 git push // 推送远端 当然，如果你不愿意在提交代码的时候进行rebase操作，你可以将git commit暂存操作换乘git stash暂存，这将使你的rebase过程变的无比顺利\n常见问题 提交代码 当进行了一个阶段的开发工作之后，就会需要对代码进行提交操作，推送到远端分支，这部分工作当然可以交给IDE来完成，不过我更推荐使用命令的形式，来更多的理解git的工作原理\n流程：暂存代码-\u0026gt;提交到本地仓库-\u0026gt;推送到远端分支\n# 1. 暂存代码：所有变化提交到暂存区 git add . # 2. 提交到本地仓库，这步需要简介且明确的写出本次提交的所有内容 git commit -m \u0026#34;本次提交内容的注释说明\u0026#34; # 3. 推送到远端分支 git push \u0026lt;远程主机名\u0026gt; \u0026lt;本地分支名\u0026gt;:\u0026lt;远程分支名\u0026gt; # 如果你看过了前面的内容后，应该可以轻松地简化这行命令 解决冲突 如果你充分理解了分支操作的本质，就会对冲突的解决应对自如，这里还是给出拉取代码时出现代码冲突情况的解决办法：\n流程：暂存(压栈)-\u0026gt;拉取代码-\u0026gt;释放代码（弹栈）-\u0026gt;手动合并冲突代码\n# 如果本地代码与线上代码有冲突，git pull 是会报错，如下： # error: Your local changes to \u0026#39;-----\u0026#39; would be overwritten by merge. Aborting.Please, commit your changes or stash them before you can merge. # 那么接下来，将是你需要做的几步： # 1. 将本地代码暂存，将工作区代码恢复到上一个版本 git stash # 2. 拉取代码，将工作区代码更新为远端最新版本 git pull # 3. 释放代码，也就是弹栈，将之前暂存的代码取出 git stash pop # 4. 手动合并代码，如果使用ide工具进行，这项工作将变的更加容易 # 5. 查看代码状态，会展示你这次合并代码过程中又对哪些文件进行了修改 git status # 6. 之后就是继续进行开发工作，再对新代码进行add、commit操作啦~^v^ 将本地项目提交到远程仓库（远程仓库是空项目） # 1. 先进入项目文件夹 cd 当前项目的完整路径 # 2. 初始化这个目录变成git可以管理的仓库 git init # 3. 暂存并提交代码 git add . git commit -m \u0026#34;Init Project\u0026#34; # 4. 关联到远程库 git remote add origin \u0026lt;你的远程库地址\u0026gt; # 5. 获取远程库与本地同步合并（如果远程库不为空必须做这一步，否则后面的提交会失败） git pull origin master # 6. 把本地库的内容推送到远程，使用 git push命令，实际上是把当前分支master推送到远程。执行此命令后会要求输入用户名、密码，验证通过后即开始上传。 git push -u origin master ","permalink":"http://localhost:1313/posts/learn4git/","summary":"\u003cblockquote\u003e\n\u003cp\u003e日常使用Git操作，随笔整理持续更新\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Learn4git"}]